{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False, False,  True,  True,  True,  True, False,  True,\n",
       "          False, False,  True,  True, False, False,  True, False, False,  True,\n",
       "           True,  True, False,  True, False,  True, False, False,  True,  True,\n",
       "          False, False, False,  True,  True, False,  True, False,  True,  True,\n",
       "          False, False,  True, False,  True,  True, False, False, False,  True,\n",
       "          False,  True,  True, False, False,  True, False,  True,  True,  True,\n",
       "           True]]),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 56, 57, 58, 59, 60]),\n",
       " tensor([ 0,  1,  2,  3,  8, 10, 11, 14, 15, 17, 18, 22, 24, 26, 27, 30, 31, 32,\n",
       "         35, 37, 40, 41, 43, 46, 47, 48, 50, 53, 54, 56]),\n",
       " tensor([3]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机选择一辆车\n",
    "import random\n",
    "import torch\n",
    "mask_veh = torch.randint(2, (1, 61)).bool()\n",
    "\n",
    "index = torch.arange(0, 61)\n",
    "\n",
    "available_index = torch.masked_select(index, ~mask_veh)\n",
    "\n",
    "random_index = random.choice(available_index)[None]\n",
    "\n",
    "mask_veh, index, available_index, random_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_time: tensor([[[100.]],\n",
      "\n",
      "        [[ 40.]]], device='cuda:0')\n",
      "context_o: tensor([[[1.]],\n",
      "\n",
      "        [[0.]]], device='cuda:0')\n",
      "index: tensor([[[0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1]]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.7719,   1.4574,   0.4904,  -1.4429,   1.3310,   1.2217,   1.0000,\n",
       "          100.0000]],\n",
       "\n",
       "        [[  0.8043,  -0.8615,  -0.6384,   0.7062,  -1.6867,  -2.2006,   0.0000,\n",
       "           40.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate_demo_1\n",
    "# [batch_size, graph_node, embedding_size], [2, 3, 6]\n",
    "embeddings = torch.tensor([[[ 0.7719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7716,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7719,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217]],\n",
    "         [[ 0.8358, -0.5840, -0.8632,    0.6978, -1.2706, -1.4171],\n",
    "         [ 0.8043, -0.8615, -0.6384,    0.7062, -1.6867, -2.2006],\n",
    "         [ 0.5360, -0.2593, -0.9840,    0.7619, -0.4540, -0.2393]]],\n",
    "       device='cuda:0')\n",
    "current_node = torch.tensor([[ 0,  1,  2], [0,  1,  2]], device='cuda:0')   # 所有车辆上一步所在结点\n",
    "batch_size, num_veh = current_node.size()   # 2, 3\n",
    "capacity = torch.tensor([[1., 1., 1.],[4., 4., 4.]], device='cuda:0')   # 所有车辆原始容量\n",
    "used_capacity = torch.tensor([[0., 1., 0.], [0., 4., 3.]], device='cuda:0') # 所有车辆已使用容量\n",
    "veh_passed_time = torch.tensor([[100., 0., 50.], [20., 40., 30.]], device='cuda:0') # 所有车辆已行驶时间\n",
    "veh = torch.tensor([0, 1], device='cuda:0') # 当前步选定车辆\n",
    "\n",
    "time = torch.zeros((batch_size, 1, 1), device=veh_passed_time.device)\n",
    "for i in range(0, veh.size(-1)):\n",
    "    time[i, 0, 0] = veh_passed_time[i, veh[i]]\n",
    "print('context_time:', time) # tensor([[[100.]], [[ 40.]]], device='cuda:0') [2, 1, 1]\n",
    "o_t = (capacity[torch.arange(batch_size), veh] - used_capacity[torch.arange(batch_size), veh]).unsqueeze(0).transpose(0, 1).unsqueeze(-1)\n",
    "print('context_o:', o_t) # tensor([[[1.]], [[0.]]], device='cuda:0') [2, 1, 1]\n",
    "\n",
    "\n",
    "index = current_node[torch.arange(batch_size), veh].contiguous().view(batch_size, 1, 1).expand(batch_size, 1, embeddings.size(-1)) \n",
    "print(\"index:\", index) # tensor([[[0, 0, 0, 0, 0, 0]], [[1, 1, 1, 1, 1, 1]]], device='cuda:0')\n",
    "\n",
    "torch.cat(\n",
    "    (\n",
    "        torch.gather(embeddings, 1, index),\n",
    "        o_t,\n",
    "        time\n",
    "    )\n",
    "    ,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding's size: torch.Size([2, 23, 6])\n",
      "coords's size: torch.Size([2, 23, 2])\n",
      "batch_size: 2 num_veh: 3\n",
      "route_index: [tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0')]\n",
      "route_embeddings: [tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from haversine import haversine\n",
    "\n",
    "def gps_distance(pt1, pt2):\n",
    "    r = haversine((pt1[1], pt1[0]), (pt2[1], pt2[0]), 'm')     # (latitude, longitude)   默认单位为km\n",
    "    return r\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# simulate_demo_2\n",
    "# [batch_size, graph_node, embedding_size], [2, 23, 6] veh_node:3 graph_node:10 new_graph_node:10\n",
    "embeddings = torch.tensor([[[ 0.7711,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7712,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7713,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7714,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7715,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7716,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7717,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7718,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7719,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7710,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7726,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7319,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7746,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.9719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.5716,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.4719,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.5719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7716,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.3719,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.2719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7816,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7726,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213]],\n",
    "         [[ 0.7711,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7712,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7713,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7714,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7715,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7716,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7717,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7718,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7719,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7710,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7726,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7319,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7746,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.9719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.5716,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.4719,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.5719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7716,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.3719,  1.4574,  0.4904,   -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.2719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7816,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213],\n",
    "         [ 0.7719,  1.4574,  0.4904,  -1.4429,  1.3310,  1.2217],\n",
    "         [ 0.7726,  1.4572,  0.4895,   -1.4425,  1.3301,  1.2213]]],device='cuda:0')\n",
    "print(\"embedding's size:\", embeddings.size())\n",
    "coords = torch.tensor([[[-122.4100772,   37.7880844],\n",
    "         [-122.3950575,   37.777057],\n",
    "         [-122.4071627,   37.779736],\n",
    "         \n",
    "         [-122.40956,   37.7879],\n",
    "         [-122.40863,   37.78982],\n",
    "         [-122.41362,   37.78674],\n",
    "         [-122.41982,   37.78674],\n",
    "         [-122.39538,   37.77667],\n",
    "         \n",
    "         [-122.39273,   37.77874],\n",
    "         [-122.39538,   37.77667],\n",
    "         [-122.39566,   37.77646],\n",
    "         [-122.39515,   37.78087],\n",
    "         [-122.40899,   37.78119],\n",
    "         \n",
    "         [-122.38877,   37.77949],\n",
    "         [-122.41636,   37.78577],\n",
    "         [-122.39318,   37.78221],\n",
    "         [-122.40563,   37.75687],\n",
    "         [-122.39738,   37.79452],\n",
    "         \n",
    "         [-122.40396,   37.77370],\n",
    "         [-122.42042,   37.77973],\n",
    "         [-122.39703,   37.78874],\n",
    "         [-122.39477,   37.78900],\n",
    "         [-122.41298,   37.76872]],\n",
    "                       \n",
    "         [[-122.4100772,   37.7880844],\n",
    "         [-122.3950575,   37.777057],\n",
    "         [-122.4071627,   37.779736],\n",
    "         \n",
    "         [-122.40956,   37.7879],\n",
    "         [-122.40863,   37.78982],\n",
    "         [-122.41362,   37.78674],\n",
    "         [-122.41982,   37.78674],\n",
    "         [-122.39538,   37.77667],\n",
    "         \n",
    "         [-122.39273,   37.77874],\n",
    "         [-122.39538,   37.77667],\n",
    "         [-122.39566,   37.77646],\n",
    "         [-122.39515,   37.78087],\n",
    "         [-122.40899,   37.78119],\n",
    "         \n",
    "         [-122.38877,   37.77949],\n",
    "         [-122.41636,   37.78577],\n",
    "         [-122.39318,   37.78221],\n",
    "         [-122.40563,   37.75687],\n",
    "         [-122.39738,   37.79452],\n",
    "         \n",
    "         [-122.40396,   37.77370],\n",
    "         [-122.42042,   37.77973],\n",
    "         [-122.39703,   37.78874],\n",
    "         [-122.39477,   37.78900],\n",
    "         [-122.41298,   37.76872]]],device='cuda:0')\n",
    "print(\"coords's size:\", coords.size())\n",
    "# current_route = torch.tensor(\n",
    "#     [[[0, 4, 3, 13, 14],  \n",
    "#       [1, 7, 17],  \n",
    "#       [2, 6, 5, 15, 16]]], device='cuda:0')   # 所有车辆上一步的路线\n",
    "\n",
    "current_route = [[[0, 4, 3, 13, 14],  \n",
    "      [1, 7, 8, 17, 9],  \n",
    "      [2, 6, 5, 15, 16]],\n",
    "      [[0, 4, 3, 13, 14],  \n",
    "      [1, 7, 17],  \n",
    "      [2, 6, 9, 5, 15, 16]]]\n",
    "\n",
    "current_route_loc =  [[[] for j in range(num_veh)] for i in range(batch_size)]\n",
    "for i in range(0, batch_size):\n",
    "      for j in range(0, num_veh):\n",
    "            for k in range(0, len(current_route[i][j])):\n",
    "                  current_route_loc[i][j].append(coords[i, current_route[i][j][k]])\n",
    "# print(\"current_route_loc:\",current_route_loc)\n",
    "\n",
    "current_route_time_cost = [[[] for j in range(num_veh)] for i in range(batch_size)]\n",
    "# init_route_time\n",
    "SPEED = 1000 / 3600\n",
    "for i in range(0, batch_size):\n",
    "      for j in range(0, len(current_route_loc[i])):\n",
    "            for k in range(0, len(current_route_loc[i][j]) - 1):\n",
    "                  time_cost = gps_distance(current_route_loc[i][j][k], current_route_loc[i][j][k+1]) / SPEED\n",
    "                  current_route_time_cost[i][j].append(time_cost)\n",
    "# print(\"current_route_time_cost:\",current_route_time_cost)\n",
    "\n",
    "batch_size, num_veh = len(current_route), len(current_route[0])\n",
    "print(\"batch_size:\", batch_size, \"num_veh:\", num_veh)\n",
    "capacity = torch.tensor([[4., 4., 4.], [4., 4., 4.]], device='cuda:0')   # 所有车辆原始容量\n",
    "used_capacity = torch.tensor([[2., 3., 2.], [2., 1., 3.]], device='cuda:0') # 所有车辆已使用容量\n",
    "# veh_passed_time = torch.tensor([[100., 0., 50.], [20., 40., 30.]], device='cuda:0') # 所有车辆已行驶时间?\n",
    "veh = torch.tensor([1, 2], device='cuda:0') # 当前步选定车辆 选定1号车\n",
    "\n",
    "# time = torch.zeros((batch_size, 1, 1), device=veh_passed_time.device) # time应该怎么拼接？\n",
    "# for i in range(0, veh.size(-1)):\n",
    "#     time[i, 0, 0] = veh_passed_time[i, veh[i]]\n",
    "# print('context_time:', time) # tensor([[[100.]], [[ 40.]]], device='cuda:0') [2, 1, 1]\n",
    "# o_t = (capacity[torch.arange(batch_size), veh] - used_capacity[torch.arange(batch_size), veh]).unsqueeze(0).transpose(0, 1).unsqueeze(-1)\n",
    "# print('context_o:', o_t) # tensor([[[1.]], [[0.]]], device='cuda:0') [2, 1, 1]\n",
    "\n",
    "# compute query\n",
    "route_index = []\n",
    "for i in range(0, veh.size(-1)):\n",
    "      route = torch.tensor(current_route[i][veh[i]], device='cuda:0')\n",
    "      route_index.append(route.contiguous().view(route.size(-1), 1).expand(-1, embeddings.size(-1)))\n",
    "print(\"route_index:\", route_index)\n",
    "\n",
    "route_embeddings = []\n",
    "for index, value in enumerate(route_index):\n",
    "      route_embeddings.append(torch.gather(embeddings[index, :, :], 0, value))\n",
    "print(\"route_embeddings:\", route_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited's size: torch.Size([2, 1, 20]) demand's size: torch.Size([2, 20]) to_delivery's size: torch.Size([2, 3, 20])\n",
      "plan_route: [1, 7, 8, 17, 9]\n",
      "plan_route_loc: [tensor([-122.3951,   37.7771], device='cuda:0'), tensor([-122.3954,   37.7767], device='cuda:0'), tensor([-122.3927,   37.7787], device='cuda:0'), tensor([-122.3974,   37.7945], device='cuda:0'), tensor([-122.3954,   37.7767], device='cuda:0')]\n",
      "plan_route_time: [185.8476260346732, 1178.6249395332716, 6486.082766963793, 7174.434205410446]\n",
      "plan_route_acc_time: [185.8476260346732, 1364.4725655679447, 7850.555332531738, 15024.989537942183]\n",
      "tensor([[[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]]], device='cuda:0')\n",
      "tensor([[[1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# compute glimpse_key and glimpse_value\n",
    "\n",
    "# how to mask node?\n",
    "visited = torch.tensor([[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]],\n",
    "                        [[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]],\n",
    "       device='cuda:0', dtype=torch.uint8)\n",
    "demand = torch.tensor([[ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  \n",
    "                         0.,  0.,  0.,  0.,  0., -1., -1., -1., -1., -1.],\n",
    "                       [ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  \n",
    "                         0.,  0.,  0.,  0.,  0., -1., -1., -1., -1., -1.]],\n",
    "       device='cuda:0')\n",
    "time = torch.tensor([[ 0.,  0.,  0.,  0.,  0.,  10000.,  10000.,  10000.,  15000.,  20000.,  \n",
    "                         0.,  0.,  0.,  0.,  0., 20000., 20000., 20000., 30000., 40000.],\n",
    "                       [ 0.,  0.,  0.,  0.,  0., 10000.,  10000.,  10000.,  15000.,  20000.,  \n",
    "                         0.,  0.,  0.,  0.,  0., 20000., 20000., 20000., 30000., 40000.]],\n",
    "       device='cuda:0')\n",
    "to_delivery = torch.tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                             [1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "                            [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                             [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]], \n",
    "        device='cuda:0')\n",
    "ids=torch.arange(batch_size, dtype=torch.int64, device=demand.device)[:, None]\n",
    "print(\"visited's size:\", visited.size(), \"demand's size:\", demand.size(), \"to_delivery's size:\", to_delivery.size())\n",
    "\n",
    "visited_loc = visited[:, :, :]\n",
    "batch_size = visited_loc.size(0)\n",
    "pre_route = current_route\n",
    "\n",
    "invalid_demand = []\n",
    "exceeds_cap = []\n",
    "delivery_for_veh = []\n",
    "mask = []\n",
    "for i in range(0, batch_size):\n",
    "    graph_size = demand[i, :].size(-1)\n",
    "    num_veh = capacity[i, :].size(-1)\n",
    "    # print(\"graph_size:\", graph_size, \"num_veh:\", num_veh)\n",
    "\n",
    "    # capacity\n",
    "    plan_route = current_route[i][veh[i]] # [1, 7, 17]\n",
    "    plan_route_loc = current_route_loc[i][veh[i]]\n",
    "    plan_route_time = current_route_time_cost[i][veh[i]]\n",
    "    plan_route_acc_time = plan_route_time[:]\n",
    "    for k in range(1, len(plan_route_acc_time)):\n",
    "        plan_route_acc_time[k] += plan_route_acc_time[k-1]\n",
    "\n",
    "    if i == 0:\n",
    "        print(\"plan_route:\", plan_route)\n",
    "        print(\"plan_route_loc:\", plan_route_loc)\n",
    "        print(\"plan_route_time:\", plan_route_time)\n",
    "        print(\"plan_route_acc_time:\", plan_route_acc_time)\n",
    "    plan_route_length = len(plan_route)\n",
    "    \n",
    "    cur_capacity = (capacity[i, veh[i]] - used_capacity[i, veh[i]]).repeat(plan_route_length, 1).squeeze(1)\n",
    "    for k in range(1, plan_route_length):\n",
    "        if (plan_route[k] >= (num_veh + graph_size // 2)) and (plan_route[k] < (num_veh + graph_size)):\n",
    "            cur_capacity[k] = cur_capacity[k-1] + 1\n",
    "    # print(\"current_capacity:\", cur_capacity.size(), cur_capacity)\n",
    "\n",
    "    # demand == 0\n",
    "    invalid_demand.append((demand[ids[i], :] == 0)[..., None].repeat(1, 1, plan_route_length)) # [1, graph_size, plan_route_length]\n",
    "\n",
    "    # demand > remain capacity\n",
    "    route_demand = demand[ids[i], :].unsqueeze(-1).expand(-1, -1, plan_route_length)\n",
    "    exceeds_cap.append(route_demand > cur_capacity[None, None, :].expand_as(route_demand))\n",
    "\n",
    "    # is_to_delivery: delivery node can only be inserted after the corresponding pickup node \n",
    "    cur_delivery = to_delivery[i, veh[i], :][None, :, None].repeat(1, 1, plan_route_length)\n",
    "    pick_index = (1 - to_delivery[i, veh[i], :])[0:graph_size//2].nonzero().squeeze(-1).tolist()\n",
    "    for pick_node in pick_index:\n",
    "        k = plan_route.index(pick_node + num_veh)\n",
    "        cur_delivery[:, pick_node + graph_size//2, 0:k] = 0\n",
    "    delivery_for_veh.append(1 - cur_delivery)\n",
    "\n",
    "    # is_visited\n",
    "    is_visited = visited_loc[i].unsqueeze(-1).expand(-1, -1, plan_route_length)\n",
    "    \n",
    "    mask_pos = is_visited | invalid_demand[i] | exceeds_cap[i] | delivery_for_veh[i]\n",
    "    print(mask_pos)\n",
    "    \n",
    "    # time\n",
    "    avail_pos = (1 - mask_pos).nonzero()\n",
    "    for k in range(0, avail_pos.size(0)): # [batch_id, node_index, insert_position]\n",
    "        insert_pos = avail_pos[k, 2]\n",
    "        insert_node = avail_pos[k, 1] # coords中的坐标包含车辆的初始结点\n",
    "        time_cost = gps_distance(plan_route_loc[insert_pos], coords[i, insert_node+num_veh, :]) / SPEED # 需要抛异常吗\n",
    "        if insert_pos > 0:\n",
    "            time_cost += plan_route_acc_time[insert_pos-1]\n",
    "        if insert_node < graph_size//2 and time_cost > time[i, insert_node]:\n",
    "            mask_pos[:, insert_node, insert_pos] = 1\n",
    "    \n",
    "    mask.append(mask_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0,  7,  0],\n",
      "        [ 0,  7,  1],\n",
      "        [ 0,  7,  2],\n",
      "        [ 0,  8,  0],\n",
      "        [ 0,  8,  1],\n",
      "        [ 0,  8,  2],\n",
      "        [ 0,  8,  3],\n",
      "        [ 0,  9,  0],\n",
      "        [ 0,  9,  1],\n",
      "        [ 0,  9,  2],\n",
      "        [ 0,  9,  3],\n",
      "        [ 0,  9,  4],\n",
      "        [ 0, 15,  2],\n",
      "        [ 0, 15,  3],\n",
      "        [ 0, 15,  4],\n",
      "        [ 0, 16,  4]], device='cuda:0'), tensor([[ 0,  5,  0],\n",
      "        [ 0,  7,  0],\n",
      "        [ 0,  8,  0],\n",
      "        [ 0,  8,  1],\n",
      "        [ 0,  9,  0],\n",
      "        [ 0,  9,  1],\n",
      "        [ 0,  9,  2],\n",
      "        [ 0, 16,  2],\n",
      "        [ 0, 16,  3],\n",
      "        [ 0, 16,  4],\n",
      "        [ 0, 16,  5]], device='cuda:0')]\n",
      "insert_route_index: [[tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [10, 10, 10, 10, 10, 10],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [10, 10, 10, 10, 10, 10],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [10, 10, 10, 10, 10, 10],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [11, 11, 11, 11, 11, 11],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [11, 11, 11, 11, 11, 11],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [11, 11, 11, 11, 11, 11],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [11, 11, 11, 11, 11, 11],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [12, 12, 12, 12, 12, 12],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [12, 12, 12, 12, 12, 12],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [12, 12, 12, 12, 12, 12],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [12, 12, 12, 12, 12, 12],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [12, 12, 12, 12, 12, 12]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [18, 18, 18, 18, 18, 18],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [18, 18, 18, 18, 18, 18],\n",
      "        [ 9,  9,  9,  9,  9,  9]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [18, 18, 18, 18, 18, 18]], device='cuda:0'), tensor([[ 1,  1,  1,  1,  1,  1],\n",
      "        [ 7,  7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [17, 17, 17, 17, 17, 17],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [19, 19, 19, 19, 19, 19]], device='cuda:0')], [tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 8,  8,  8,  8,  8,  8],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [10, 10, 10, 10, 10, 10],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [11, 11, 11, 11, 11, 11],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [11, 11, 11, 11, 11, 11],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [12, 12, 12, 12, 12, 12],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [12, 12, 12, 12, 12, 12],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [12, 12, 12, 12, 12, 12],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [19, 19, 19, 19, 19, 19],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [19, 19, 19, 19, 19, 19],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [19, 19, 19, 19, 19, 19],\n",
      "        [16, 16, 16, 16, 16, 16]], device='cuda:0'), tensor([[ 2,  2,  2,  2,  2,  2],\n",
      "        [ 6,  6,  6,  6,  6,  6],\n",
      "        [ 9,  9,  9,  9,  9,  9],\n",
      "        [ 5,  5,  5,  5,  5,  5],\n",
      "        [15, 15, 15, 15, 15, 15],\n",
      "        [16, 16, 16, 16, 16, 16],\n",
      "        [19, 19, 19, 19, 19, 19]], device='cuda:0')]]\n",
      "insert_route_embeddings: [[tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7726,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7726,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7726,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7319,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7319,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7319,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7319,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.3719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.3719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.3719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7712,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7718,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.2719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0')], [tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7726,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7319,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7319,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7746,  1.4572,  0.4895, -1.4425,  1.3301,  1.2213],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.2719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.2719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.2719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0'), tensor([[ 0.7713,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7717,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7710,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.7716,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.4719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.5719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217],\n",
      "        [ 0.2719,  1.4574,  0.4904, -1.4429,  1.3310,  1.2217]],\n",
      "       device='cuda:0')]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# route embedding after insert new node\n",
    "final_avail_pos = []\n",
    "for mask_pos in mask:\n",
    "    final_avail_pos.append((1-mask_pos).nonzero())\n",
    "print(final_avail_pos)\n",
    "\n",
    "# compute key and value\n",
    "insert_route_index = [[] for i in range(veh.size(-1))]\n",
    "for i in range(0, veh.size(-1)):\n",
    "      for k in range(0, final_avail_pos[i].size(0)):\n",
    "            plan_route = current_route[i][veh[i]].copy() # 需要向嵌套列表中插入新的结点 计算所有可能的路线 不能修改原来的计划路线\n",
    "            insert_index = final_avail_pos[i][k, 2].item() + 1\n",
    "            insert_node = final_avail_pos[i][k, 1].item() + num_veh\n",
    "            # print(insert_index, insert_node)\n",
    "            plan_route.insert(insert_index, insert_node)\n",
    "            insert_route = torch.tensor(plan_route, device='cuda:0')\n",
    "            insert_route_index[i].append(insert_route.contiguous().view(insert_route.size(-1), 1).expand(-1, embeddings.size(-1)))\n",
    "print(\"insert_route_index:\", insert_route_index)\n",
    "\n",
    "insert_route_embeddings = [[] for i in range(veh.size(-1))]\n",
    "for i in range(0, veh.size(-1)):\n",
    "      for value in insert_route_index[i]:\n",
    "            insert_route_embeddings[i].append(torch.gather(embeddings[i, :, :], 0, value))\n",
    "print(\"insert_route_embeddings:\", insert_route_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6.], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(1,3)\n",
    "x2 = torch.randn(1,3)\n",
    "x1, x2, x1 + x2\n",
    "\n",
    "x = torch.tensor([3., 3., 3., 3.], device='cuda:0')\n",
    "for i in range(1, x.size(-1)):\n",
    "    x[i] = x[i-1] + 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "vh_request = {\n",
    "    148: [{'id': 34987, 'o_x': -122.44013999999999, 'o_y': 37.79652, 'd_x': -122.43966, 'd_y': 37.78468, 'status': 'unassigned'}, \n",
    "          {'id': 422238, 'o_x': -122.43321999999999, 'o_y': 37.79743, 'd_x': -122.41548, 'd_y': 37.778940000000006, 'status': 'unassigned'}, \n",
    "          {'id': 254292, 'o_x': -122.43468, 'o_y': 37.7972, 'd_x': -122.41851000000001, 'd_y': 37.77202, 'status': 'unassigned'}], \n",
    "    335: [{'id': 34987, 'o_x': -122.44013999999999, 'o_y': 37.79652, 'd_x': -122.43966, 'd_y': 37.78468, 'status': 'unassigned'}, \n",
    "          {'id': 312484, 'o_x': -122.39515, 'o_y': 37.78087, 'd_x': -122.39477, 'd_y': 37.789, 'status': 'unassigned'}], \n",
    "    416: [{'id': 57379, 'o_x': -122.39538, 'o_y': 37.77667, 'd_x': -122.39738, 'd_y': 37.79452, 'status': 'unassigned'}, \n",
    "          {'id': 123043, 'o_x': -122.40700000000001, 'o_y': 37.78942, 'd_x': -122.3972, 'd_y': 37.79367, 'status': 'unassigned'}, \n",
    "          {'id': 164196, 'o_x': -122.39703, 'o_y': 37.785579999999996, 'd_x': -122.39438999999999, 'd_y': 37.794129999999996,  'status': 'unassigned'}]\n",
    "    }\n",
    "vehicles = [148, 335, 416]\n",
    "graph = (\n",
    "    {'id': 34987, 'o_x': -122.44013999999999, 'o_y': 37.79652, 'd_x': -122.43966, 'd_y': 37.78468, 'status': 'unassigned'},\n",
    "    {'id': 422238, 'o_x': -122.43321999999999, 'o_y': 37.79743, 'd_x': -122.41548, 'd_y': 37.778940000000006, 'status': 'unassigned'},\n",
    "    {'id': 254292, 'o_x': -122.43468, 'o_y': 37.7972, 'd_x': -122.41851000000001, 'd_y': 37.77202, 'status': 'unassigned'},\n",
    "    {'id': 312484, 'o_x': -122.39515, 'o_y': 37.78087, 'd_x': -122.39477, 'd_y': 37.789, 'status': 'unassigned'},\n",
    "    {'id': 57379, 'o_x': -122.39538, 'o_y': 37.77667, 'd_x': -122.39738, 'd_y': 37.79452, 'status': 'unassigned'},\n",
    "    {'id': 123043, 'o_x': -122.40700000000001, 'o_y': 37.78942, 'd_x': -122.3972, 'd_y': 37.79367, 'status': 'unassigned'},\n",
    "    {'id': 164196, 'o_x': -122.39703, 'o_y': 37.785579999999996, 'd_x': -122.39438999999999, 'd_y': 37.794129999999996,  'status': 'unassigned'}\n",
    ")\n",
    "\n",
    "to_visited = torch.zeros(len(vehicles), len(graph)*2)\n",
    "print(to_visited)\n",
    "\n",
    "for veh, requests in vh_request.items():\n",
    "      veh_index = vehicles.index(veh)\n",
    "      for req in requests:\n",
    "            req_index = graph.index(req)\n",
    "            to_visited[veh_index, req_index] = 1\n",
    "print(to_visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6005], device='cuda:0'),\n",
       " tensor([8], device='cuda:0'),\n",
       " tensor([8], device='cuda:0'))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select_node\n",
    "\n",
    "probs = torch.tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5123e-02,\n",
    "         0.0000e+00, 0.0000e+00, 6.0046e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 1.3835e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 2.0752e-06, 0.0000e+00, 2.0252e-04, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4002e-04, 0.0000e+00,\n",
    "         8.6334e-05, 0.0000e+00, 2.4989e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 3.3174e-01, 3.3238e-05, 0.0000e+00, 2.7028e-04,\n",
    "         0.0000e+00, 0.0000e+00, 1.3705e-04, 0.0000e+00, 1.4655e-04, 0.0000e+00,\n",
    "         6.8412e-07, 0.0000e+00, 2.7100e-06, 2.3945e-06, 0.0000e+00, 6.5161e-05,\n",
    "         5.1309e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8323e-06, 4.2844e-05,\n",
    "         0.0000e+00, 1.0670e-04, 0.0000e+00, 9.4663e-05, 1.0154e-04, 0.0000e+00,\n",
    "         0.0000e+00, 6.3411e-04, 6.5550e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
    "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
    "       device='cuda:0')\n",
    "value,index = probs.max(1)\n",
    "value, index, probs.multinomial(1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 1, 1])\n",
    "y = torch.tensor([1, 1, 0])\n",
    "\n",
    "print(y.nonzero().squeeze(-1))\n",
    "visited = torch.tensor([[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
    "       device='cuda:0', dtype=torch.uint8)\n",
    "z = torch.tensor([[2], [18], [33]])\n",
    "visited[0, :, z]\n",
    "mask = torch.tensor([True, False])\n",
    "if mask.all():\n",
    "    print('haha ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "batch_size = 2\n",
    "num_veh = 3\n",
    "mask = torch.tensor([[True, False, False], [False, False, False]])\n",
    "vehicles = torch.arange(0, num_veh, dtype=torch.int64)\n",
    "available_vehicles = torch.arange(0, batch_size, dtype=torch.int64)\n",
    "for i in range(batch_size):\n",
    "    available_vehicles[i] = random.choice(vehicles[~mask[i]])\n",
    "available_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veh = torch.tensor([93, 66])\n",
    "veh.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 4])\n",
      "torch.Size([1, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch_size = 2\n",
    "num_veh = 3\n",
    "graph_size = 5\n",
    "length = 4\n",
    "veh = torch.tensor([0, 1])\n",
    "to_visit = torch.tensor([[[1, 1, 1, 0, 0],[1, 0, 0, 1, 1],[0, 0, 1, 1, 1]],[[1, 1, 1, 0, 0],[1, 0, 0, 1, 1],[0, 0, 1, 1, 1]]])\n",
    "for i in range(batch_size):\n",
    "    print(to_visit[i, veh[i], :][None, :, None].expand(-1, -1, length).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0, 57,  0], device='cuda:0'), tensor([ 0, 57,  0], device='cuda:0')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_avail_pos = [torch.tensor([[ 0,  2,  0],\n",
    "        [ 0, 18,  0],\n",
    "        [ 0, 20,  0],\n",
    "        [ 0, 24,  0],\n",
    "        [ 0, 36,  0],\n",
    "        [ 0, 40,  0],\n",
    "        [ 0, 44,  0],\n",
    "        [ 0, 50,  0],\n",
    "        [ 0, 57,  0],\n",
    "        [ 0, 68,  0]], device='cuda:0')]\n",
    "probs = [torch.tensor([[ 0.0250, -0.0621, -0.0477, -0.0304, -0.0158, -0.0028, -0.0179, -0.1133,\n",
    "          0.0742, -0.0226]], device='cuda:0')]\n",
    "selected = []\n",
    "batch_size = len(final_avail_pos)\n",
    "for i in range(batch_size):\n",
    "    selected.append(final_avail_pos[i][probs[i].exp()[0, :].max(0)[1]])\n",
    "    selected.append((final_avail_pos[i][probs[i].exp()[0, :].multinomial(1)]).squeeze(0))\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\develop_tools\\Anaconda3\\envs\\fleet_rs\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([16, 20], device='cuda:0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "veh = torch.tensor([16, 20], device='cuda:0')\n",
    "batch_size = 2\n",
    "prev_a = torch.tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
    "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
    "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
    "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
    "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
    "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
    "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
    "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
    "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121],\n",
    "         [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
    "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
    "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
    "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
    "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
    "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
    "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
    "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
    "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121],\n",
    "         ], device='cuda:0')\n",
    "prev_a[torch.arange(batch_size), veh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tensor([1, 1, 1])\n",
    "min((1 - mask).nonzero().shape) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited = torch.tensor([[[1, 1, 0, 0, 0, 0]]],\n",
    "       device='cuda:0', dtype=torch.uint8)\n",
    "to_visit = torch.tensor([[[1, 0, 0, 1, 1, 1],\n",
    "          [0, 1, 0, 1, 1, 1],\n",
    "          [0, 0, 1, 1, 1, 1]]],\n",
    "       device='cuda:0', dtype=torch.uint8)\n",
    "visited.size(), to_visit.size()\n",
    "if visited[0, :, (1 - to_visit[0, 1, :]).nonzero()].all():\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "(1 - to_visit[0, 0, :]).nonzero().squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19],\n",
      "        [39],\n",
      "        [59]], device='cuda:0')\n",
      "tensor([[[1],\n",
      "         [1],\n",
      "         [1]]], device='cuda:0', dtype=torch.uint8)\n",
      "mask 了\n",
      "tensor([[19],\n",
      "        [39],\n",
      "        [59]], device='cuda:0')\n",
      "tensor([[[1],\n",
      "         [1],\n",
      "         [1]]], device='cuda:0', dtype=torch.uint8)\n",
      "mask 了\n"
     ]
    }
   ],
   "source": [
    "visited_loc = torch.tensor([[[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
    "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]]],\n",
    "       device='cuda:0', dtype=torch.uint8)\n",
    "to_visit = torch.tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], # 23个\n",
    "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
    "       device='cuda:0', dtype=torch.uint8)\n",
    "visited_loc.size(), to_visit.size()\n",
    "for j in range(2):\n",
    "    print((1 - to_visit[0, j, :]).nonzero().squeeze(0))\n",
    "    print(visited_loc[0, :, (1 - to_visit[0, j, :]).nonzero().squeeze(0)])\n",
    "    if visited_loc[0, :, (1 - to_visit[0, j, :]).nonzero().squeeze(0)].all():\n",
    "        print(\"mask 了\")\n",
    "    else:\n",
    "        print('没mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "29687 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m459686\u001b[39m, \u001b[38;5;241m12645\u001b[39m, \u001b[38;5;241m201126\u001b[39m, \u001b[38;5;241m324284\u001b[39m, \u001b[38;5;241m261858\u001b[39m, \u001b[38;5;241m41095\u001b[39m, \u001b[38;5;241m251989\u001b[39m, \u001b[38;5;241m206635\u001b[39m, \u001b[38;5;241m189606\u001b[39m, \u001b[38;5;241m56415\u001b[39m, \u001b[38;5;241m384120\u001b[39m, \u001b[38;5;241m235595\u001b[39m, \u001b[38;5;241m72323\u001b[39m, \u001b[38;5;241m269839\u001b[39m, \u001b[38;5;241m469617\u001b[39m, \u001b[38;5;241m85706\u001b[39m, \u001b[38;5;241m246488\u001b[39m, \u001b[38;5;241m466194\u001b[39m, \u001b[38;5;241m210468\u001b[39m, \u001b[38;5;241m258975\u001b[39m, \u001b[38;5;241m199980\u001b[39m, \u001b[38;5;241m239452\u001b[39m, \u001b[38;5;241m301387\u001b[39m, \u001b[38;5;241m332843\u001b[39m, \u001b[38;5;241m211398\u001b[39m, \u001b[38;5;241m74754\u001b[39m, \u001b[38;5;241m330661\u001b[39m, \u001b[38;5;241m392623\u001b[39m, \u001b[38;5;241m214411\u001b[39m, \u001b[38;5;241m310170\u001b[39m, \u001b[38;5;241m313828\u001b[39m, \u001b[38;5;241m64317\u001b[39m, \u001b[38;5;241m31063\u001b[39m, \u001b[38;5;241m162402\u001b[39m, \u001b[38;5;241m274960\u001b[39m, \u001b[38;5;241m279415\u001b[39m, \u001b[38;5;241m380486\u001b[39m, \u001b[38;5;241m444456\u001b[39m, \u001b[38;5;241m229058\u001b[39m, \u001b[38;5;241m373007\u001b[39m, \u001b[38;5;241m415369\u001b[39m, \u001b[38;5;241m168589\u001b[39m, \u001b[38;5;241m315096\u001b[39m, \u001b[38;5;241m362154\u001b[39m, \u001b[38;5;241m93506\u001b[39m, \u001b[38;5;241m145059\u001b[39m, \u001b[38;5;241m411935\u001b[39m, \u001b[38;5;241m339385\u001b[39m, \u001b[38;5;241m22946\u001b[39m, \u001b[38;5;241m91509\u001b[39m, \u001b[38;5;241m79199\u001b[39m, \u001b[38;5;241m303888\u001b[39m, \u001b[38;5;241m1947\u001b[39m, \u001b[38;5;241m176629\u001b[39m, \u001b[38;5;241m117966\u001b[39m, \u001b[38;5;241m278466\u001b[39m, \u001b[38;5;241m73917\u001b[39m, \u001b[38;5;241m312484\u001b[39m, \u001b[38;5;241m281945\u001b[39m, \u001b[38;5;241m34987\u001b[39m, \u001b[38;5;241m45636\u001b[39m, \u001b[38;5;241m372317\u001b[39m, \u001b[38;5;241m437254\u001b[39m, \u001b[38;5;241m87620\u001b[39m, \u001b[38;5;241m63247\u001b[39m, \u001b[38;5;241m373006\u001b[39m, \u001b[38;5;241m224596\u001b[39m, \u001b[38;5;241m422238\u001b[39m, \u001b[38;5;241m391628\u001b[39m, \u001b[38;5;241m57379\u001b[39m, \u001b[38;5;241m123043\u001b[39m, \u001b[38;5;241m234566\u001b[39m, \u001b[38;5;241m50665\u001b[39m, \u001b[38;5;241m46688\u001b[39m, \u001b[38;5;241m465306\u001b[39m, \u001b[38;5;241m397618\u001b[39m, \u001b[38;5;241m404850\u001b[39m, \u001b[38;5;241m470529\u001b[39m, \u001b[38;5;241m149330\u001b[39m, \u001b[38;5;241m1946\u001b[39m, \u001b[38;5;241m416352\u001b[39m, \u001b[38;5;241m283885\u001b[39m, \u001b[38;5;241m460740\u001b[39m, \u001b[38;5;241m88472\u001b[39m, \u001b[38;5;241m282900\u001b[39m, \u001b[38;5;241m54076\u001b[39m, \u001b[38;5;241m163445\u001b[39m, \u001b[38;5;241m205671\u001b[39m, \u001b[38;5;241m475043\u001b[39m, \u001b[38;5;241m37198\u001b[39m, \u001b[38;5;241m440428\u001b[39m, \u001b[38;5;241m170807\u001b[39m, \u001b[38;5;241m257892\u001b[39m, \u001b[38;5;241m164196\u001b[39m, \u001b[38;5;241m113479\u001b[39m, \u001b[38;5;241m368142\u001b[39m, \u001b[38;5;241m317172\u001b[39m, \u001b[38;5;241m352360\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mid\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m29687\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: 29687 is not in list"
     ]
    }
   ],
   "source": [
    "id = [459686, 12645, 201126, 324284, 261858, 41095, 251989, 206635, 189606, 56415, 384120, 235595, 72323, 269839, 469617, 85706, 246488, 466194, 210468, 258975, 199980, 239452, 301387, 332843, 211398, 74754, 330661, 392623, 214411, 310170, 313828, 64317, 31063, 162402, 274960, 279415, 380486, 444456, 229058, 373007, 415369, 168589, 315096, 362154, 93506, 145059, 411935, 339385, 22946, 91509, 79199, 303888, 1947, 176629, 117966, 278466, 73917, 312484, 281945, 34987, 45636, 372317, 437254, 87620, 63247, 373006, 224596, 422238, 391628, 57379, 123043, 234566, 50665, 46688, 465306, 397618, 404850, 470529, 149330, 1946, 416352, 283885, 460740, 88472, 282900, 54076, 163445, 205671, 475043, 37198, 440428, 170807, 257892, 164196, 113479, 368142, 317172, 352360]\n",
    "len(id)\n",
    "id.index(29687)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89abb37f455bdde29972dcea5092f10d6af7f2ab65d58ad874a3b6309132caa5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('fleet_rs': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
